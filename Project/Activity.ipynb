{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from urllib import request \n",
    "global url\n",
    "global confidence\n",
    "url = []\n",
    "confidence = []\n",
    "\n",
    "\n",
    "url1 = \"http://www.natgeotraveller.in/six-years-and-counting/\"\n",
    "html1 = request.urlopen(url1).read().decode('utf8')\n",
    "#print(html1)\n",
    "url.append(url1)\n",
    "confidence.append(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "url2 = \"http://www.natgeotraveller.in/train-to-nowhere/\"\n",
    "html2 = request.urlopen(url2).read().decode('utf8')\n",
    "#print(html2)\n",
    "url.append(url2)\n",
    "confidence.append(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "url3 = \"http://www.natgeotraveller.in/what-dreams-may-come/\"\n",
    "html3 = request.urlopen(url3).read().decode('utf8')\n",
    "#print(html3)\n",
    "url.append(url3)\n",
    "confidence.append(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "url4 = \"http://www.natgeotraveller.in/getting-saucy-about-food/\"\n",
    "html4 = request.urlopen(url4).read().decode('utf8')\n",
    "#print(html4)\n",
    "url.append(url4)\n",
    "confidence.append(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "981\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from bs4 import BeautifulSoup\n",
    "raw1 = BeautifulSoup(html1, 'html.parser').get_text()\n",
    "tokens1 = word_tokenize(raw1)\n",
    "print(len(tokens1))\n",
    "#print(tokens1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "988\n"
     ]
    }
   ],
   "source": [
    "raw2 = BeautifulSoup(html2, 'html.parser').get_text()\n",
    "tokens2 = word_tokenize(raw2)\n",
    "print(len(tokens2))\n",
    "#print(tokens2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "927\n"
     ]
    }
   ],
   "source": [
    "raw3 = BeautifulSoup(html3, 'html.parser').get_text()\n",
    "tokens3 = word_tokenize(raw3)\n",
    "print(len(tokens3))\n",
    "#print(tokens3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1013\n"
     ]
    }
   ],
   "source": [
    "raw4 = BeautifulSoup(html4, 'html.parser').get_text()\n",
    "tokens4 = word_tokenize(raw4)\n",
    "print(len(tokens4))\n",
    "#print(tokens4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words=set(stopwords.words(\"english\"))\n",
    "filtered_words1=[]\n",
    "for w in tokens1:\n",
    "    if w not in stop_words:\n",
    "        filtered_words1.append(w)\n",
    "#print(filtered_words1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words=set(stopwords.words(\"english\"))\n",
    "filtered_words2=[]\n",
    "for w in tokens2:\n",
    "    if w not in stop_words:\n",
    "        filtered_words2.append(w)\n",
    "#print(filtered_words2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words=set(stopwords.words(\"english\"))\n",
    "filtered_words3=[]\n",
    "for w in tokens3:\n",
    "    if w not in stop_words:\n",
    "        filtered_words3.append(w)\n",
    "#print(filtered_words3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words=set(stopwords.words(\"english\"))\n",
    "filtered_words4=[]\n",
    "for w in tokens4:\n",
    "    if w not in stop_words:\n",
    "        filtered_words4.append(w)\n",
    "#print(filtered_words4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter - 1\n",
    "\n",
    "### In articles, thoughts have to be conveyed with a specific number of words - neither too low for incomplete information delivery nor too high for the user to lose interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of words:  720\n",
      "Confidence:  0.8\n",
      "Total Number of words:  736\n",
      "Confidence:  0.8\n",
      "Total Number of words:  690\n",
      "Confidence:  0.5\n",
      "Total Number of words:  760\n",
      "Confidence:  0.3\n"
     ]
    }
   ],
   "source": [
    "fw = [filtered_words1, filtered_words2, filtered_words3, filtered_words4]\n",
    "global confidence\n",
    "i=0\n",
    "for i in range(0,4):\n",
    "    if len(fw[i])>=700 and len(fw[i])<750: confidence[i] += 0.2; # 20% confidence\n",
    "    elif len(fw[i]) in range(600,700) or len(fw[i]) in range(750,800):\n",
    "        confidence[i] += 0.1;\n",
    "    print(\"Total Number of words: \", len(fw[i]))\n",
    "    print(\"Confidence: \", round(confidence[i],2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter - 2\n",
    "\n",
    "### Repeating certain words are considered to be bad from an editorial point of view as it signifies the poor vocabulary of the writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of repeated words:  108\n",
      "Confidence:  0.9\n",
      "Number of repeated words:  109\n",
      "Confidence:  0.9\n",
      "Number of repeated words:  105\n",
      "Confidence:  0.6\n",
      "Number of repeated words:  110\n",
      "Confidence:  0.3\n"
     ]
    }
   ],
   "source": [
    "global confidence\n",
    "for x in range(0,4):\n",
    "    i=0\n",
    "    repeated = [] \n",
    "    for i in range(0, len(fw[x])): \n",
    "        k=0\n",
    "        k = i + 1\n",
    "        j=k\n",
    "        for j in range(k,len(fw[x])): \n",
    "            if fw[x][i] == fw[x][j] and fw[x][i] not in repeated: \n",
    "                repeated.append(fw[x][i]) \n",
    "    print(\"Number of repeated words: \",len(repeated))\n",
    "    if len(repeated)<100: confidence[x]+=0.3\n",
    "    elif len(repeated)<105: confidence[x]+=0.2\n",
    "    elif len(repeated)<110: confidence[x]+=0.1\n",
    "    print(\"Confidence: \",round(confidence[x],2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter 3\n",
    "\n",
    "### Travel logs are essentially to provide a positive sentiment for the readers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters 4 onwards have lesser priority and contributes lesser to the overall confidence level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter 4\n",
    "\n",
    "### An article can be considered bloated if the number of adjectives are high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter 5\n",
    "\n",
    "### Number of polysyllables should be within a range where it shouldn't sound complex nor too simple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Idea from: https://medium.com/glose-team/how-to-evaluate-text-readability-with-nlp-9c04bd3f46a2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter 6\n",
    "\n",
    "### Number of words should be within a range where it shouldn't sound complex nor too simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Idea from: https://medium.com/glose-team/how-to-evaluate-text-readability-with-nlp-9c04bd3f46a2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter 7\n",
    "\n",
    "### Parts of Speech Tags count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Idea from: https://medium.com/glose-team/how-to-evaluate-text-readability-with-nlp-9c04bd3f46a2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter 8\n",
    "\n",
    "### Readability formulas - Check up on this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Idea from: https://medium.com/glose-team/how-to-evaluate-text-readability-with-nlp-9c04bd3f46a2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run this for resetting the confidence scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "global confidence\n",
    "for i in range(len(confidence)):\n",
    "    confidence[i]=0\n",
    "print(confidence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating confidences\n",
    "\n",
    "### All the scores which are cumulated till now are checked against a minimum threshold score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author of article 1 is hired\n",
      "Article  1 : http://www.natgeotraveller.in/six-years-and-counting/\n",
      "Author of article 2 is hired\n",
      "Article  2 : http://www.natgeotraveller.in/train-to-nowhere/\n"
     ]
    }
   ],
   "source": [
    "global confidence\n",
    "for i in range(0,4):\n",
    "    if confidence[i]>=0.9:\n",
    "        print(\"Author of article\", i+1, \"is hired\")\n",
    "        print(\"Article \",i+1,\":\",url[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
